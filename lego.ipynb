{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket=sess.default_bucket()\n",
    "prefix = \"lego-{}\".format(datetime.today().strftime(\"%y%m%d-%H%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "ssm = boto3.client('ssm')\n",
    "\n",
    "# expected format: {\"username\":\"xx\",\"key\":\"xxx\"}\n",
    "kaggleAPI = ssm.get_parameter(\n",
    "    Name='kaggleAPI'\n",
    ")\n",
    "kaggleAPI = json.loads(kaggleAPI.get(\"Parameter\")[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"KAGGLE_USERNAME\"] = kaggleAPI[\"username\"]\n",
    "environ[\"KAGGLE_KEY\"] = kaggleAPI[\"key\"]\n",
    "\n",
    "![ -z \"lego-brick-images.zip\" ] && rm lego-brick-images.zip\n",
    "\n",
    "!kaggle datasets download --force joosthazelzet/lego-brick-images\n",
    "!unzip -oq lego-brick-images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Training Data\n",
    "Overlay the transparent background with Gaussian noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import randrange\n",
    "\n",
    "def replace_background(fg):\n",
    "    w,h = fg.size\n",
    "\n",
    "    # Create Gaussian background\n",
    "    SHAPE = (w,h)\n",
    "\n",
    "    noise = np.random.normal(255./2,255./10,SHAPE)\n",
    "    bg = Image.fromarray(noise)\n",
    "\n",
    "    with_gaussian_background = Image.new('RGBA', (w,h), (0, 0, 0, 0))\n",
    "\n",
    "    # with_gaussian_background.paste(im, (0,0))\n",
    "    # with_gaussian_background.paste(front, (0,0), mask=front)\n",
    "\n",
    "    with_gaussian_background.paste(bg, ((with_gaussian_background.width - bg.width) // 2, (with_gaussian_background.height - bg.height) // 2))\n",
    "    with_gaussian_background.paste(fg, ((with_gaussian_background.width - fg.width) // 2, (with_gaussian_background.height - fg.height) // 2), mask=fg)\n",
    "\n",
    "    return with_gaussian_background\n",
    "\n",
    "def loop_original_images(folder):\n",
    "    dest_folder = \"processed/train/{}\".format(folder)\n",
    "    !mkdir -p \"{dest_folder}\"\n",
    "    print(\"processing images from folder: {}\".format(dest_folder))\n",
    "    names = [f for f in os.listdir('LEGO brick images/train/{}'.format(folder))]\n",
    "    count=0\n",
    "    for name in names:\n",
    "        image = Image.open(\"LEGO brick images/train/{}/{}\".format(folder, name), 'r')\n",
    "        processed = replace_background(image)\n",
    "        processed.save(dest_folder + \"/\" + name, format=\"png\")\n",
    "        count=count+1\n",
    "\n",
    "    print(\"Images processed:{}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_original_images(\"3003 Brick 2x2\")\n",
    "loop_original_images(\"3005 Brick 1x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre='LEGO brick images/train/3003 Brick 2x2/'\n",
    "post='processed/train/3003 Brick 2x2/'\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(6):\n",
    "    image_name=f'{(randrange(399)+1):04}'+\".png\"\n",
    "    old=Image.open(pre+\"/\"+image_name)\n",
    "    plt.subplot(6,4,((i+1)*2)-1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(old)\n",
    "    plt.xlabel(\"old:{}\".format(image_name))\n",
    "    new=Image.open(post+\"/\"+image_name)\n",
    "    plt.subplot(6,4,(i+1)*2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(new)\n",
    "    plt.xlabel(\"new:{}\".format(image_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"processed/valid/3003 Brick 2x2/\"\n",
    "!cp -R \"LEGO brick images/valid/3003 Brick 2x2/\" \"processed/valid/3003 Brick 2x2/\"\n",
    "!mkdir -p \"processed/valid/3005 Brick 1x1/\"\n",
    "!cp -R \"LEGO brick images/valid/3005 Brick 1x1/\" \"processed/valid/3005 Brick 1x1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_folder = \"./processed/train\"\n",
    "validation_image_folder = \"./processed/valid\"\n",
    "\n",
    "# generate .rec database\n",
    "!python im2rec.py lego_train \"$training_image_folder\" --list --recursive --pass-through --pack-label \n",
    "!python im2rec.py lego_train \"$training_image_folder\" --recursive --pass-through --pack-label \n",
    "!python im2rec.py lego_test \"$validation_image_folder\" --list --recursive --pass-through --pack-label \n",
    "!python im2rec.py lego_test \"$validation_image_folder\" --recursive --pass-through --pack-label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the RecordIO files to train and validation channels\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='lego_train.rec', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='lego_test.rec', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(training_image_folder))\n",
    "num_training_samples = sum([len(files) for r, d, files in os.walk(training_image_folder)])\n",
    "\n",
    "print(\"num_classes:{}\".format(num_classes))\n",
    "print(\"num_training_samples:{}\".format(num_training_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner \n",
    "from datetime import date\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "# training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuner():\n",
    "    from sagemaker import HyperparameterTuningJobAnalytics\n",
    "    \n",
    "    mini_batch_size_min = 16\n",
    "    mini_batch_size_max = 64\n",
    "    learning_rate_min = \"0.0001\"\n",
    "    learning_rate_max = \"1.0\"\n",
    "    optimizers = ['sgd', 'adam', 'rmsprop', 'nag']\n",
    "\n",
    "    # maximum number of training jobs\n",
    "    hpo_max_number_of_training_jobs = 50\n",
    "    # maximum number of parallel training jobs\n",
    "    hpo_max_number_of_parallel_jobs = 2\n",
    "    hpo_objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "    hpo_hyperparameter_ranges = \\\n",
    "    {\n",
    "        'learning_rate': ContinuousParameter(learning_rate_min, learning_rate_max),\n",
    "        'mini_batch_size': IntegerParameter(mini_batch_size_min, mini_batch_size_max),\n",
    "        'optimizer': CategoricalParameter(optimizers)\n",
    "    }\n",
    "    ic = sagemaker.estimator.Estimator(\n",
    "        training_image,\n",
    "        role, \n",
    "        train_instance_count=1, \n",
    "        train_instance_type='ml.p3.8xlarge', \n",
    "        input_mode= 'File',\n",
    "        output_path=s3_output_location,\n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "\n",
    "    layers=34 # [18, 34, 50, 101, 152, 200, 20, 32, 44, 56, 110]\n",
    "    epochs=1000\n",
    "\n",
    "    ic.set_hyperparameters(\n",
    "        num_layers=layers,\n",
    "        num_classes=num_classes,\n",
    "        num_training_samples=num_training_samples,\n",
    "        image_shape = \"3,200,200\",\n",
    "    # mini_batch_size=4,\n",
    "        epochs=epochs,\n",
    "    # learning_rate=0.001,\n",
    "         top_k=5,\n",
    "         precision_dtype='float32',\n",
    "         use_pretrained_model=0\n",
    "    )\n",
    "    \n",
    "    tuner_es = HyperparameterTuner(ic, \n",
    "                                   hpo_objective_metric_name, \n",
    "                                   hpo_hyperparameter_ranges,\n",
    "                                   objective_type='Maximize', \n",
    "                                   max_jobs=hpo_max_number_of_training_jobs, \n",
    "                                   max_parallel_jobs=hpo_max_number_of_parallel_jobs, \n",
    "                                   early_stopping_type='Auto',\n",
    "                                   strategy=\"Random\"\n",
    "                                  )\n",
    "\n",
    "    # run the hyperparameter tuning job\n",
    "    tuner_es.fit(data_channels, job_name=prefix, include_cls_metadata=False)\n",
    "\n",
    "    print('Hyperparameter Tuning job name: {}'.format(job_name))\n",
    "    tuner_es.wait()\n",
    "    tuner_metrics_es = HyperparameterTuningJobAnalytics(job_name)\n",
    "    tuner_metrics_es.dataframe().sort_values(['FinalObjectiveValue'], ascending=False).head(5)    \n",
    "    best_training_job_name = tuner_es.best_training_job()\n",
    "    return best_training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_hyperparameter_training():\n",
    "    ic = sagemaker.estimator.Estimator(\n",
    "        training_image,\n",
    "        role, \n",
    "        train_instance_count=1, \n",
    "        train_instance_type='ml.p3.8xlarge', \n",
    "        input_mode= 'File',\n",
    "        output_path=s3_output_location,\n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "\n",
    "    layers=34 # [18, 34, 50, 101, 152, 200, 20, 32, 44, 56, 110]\n",
    "    epochs=100\n",
    "\n",
    "    ic.set_hyperparameters(\n",
    "        num_layers=layers,\n",
    "        num_classes=num_classes,\n",
    "        num_training_samples=num_training_samples,\n",
    "        image_shape = \"3,200,200\",\n",
    "        mini_batch_size=64,\n",
    "        epochs=epochs,\n",
    "        learning_rate=0.0005,\n",
    "        top_k=5,\n",
    "        precision_dtype='float32',\n",
    "        use_pretrained_model=0\n",
    "    )\n",
    "    \n",
    "    ic.fit(inputs=data_channels, logs=True, wait=True)\n",
    "    return ic.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name=single_hyperparameter_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ic.training_job_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = sess.endpoint_from_job(\n",
    "    job_name=training_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=training_image,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attached_estimator = sagemaker.estimator.Estimator.attach(best_training_job_name)\n",
    "# attached_estimator.deploy(initial_instance_count = 1,\n",
    "#                           instance_type = 'ml.c5.4xlarge')\n",
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test/\n",
    "!unzip -o data/lego_photos.zip -d test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "names = [f for f in os.listdir('test')]\n",
    "for name in names:\n",
    "    print(\"image: {}\".format(name))\n",
    "    image = Image.open('test/' + name)\n",
    "    w,h = image.size\n",
    "    if(w>200):\n",
    "        image.thumbnail((200,200))\n",
    "    imgByteArr = io.BytesIO()\n",
    "    image.save(imgByteArr, format='PNG')\n",
    "    payload = imgByteArr.getvalue()\n",
    "    predictor.content_type = 'application/x-image'\n",
    "    result = json.loads(predictor.predict(payload))\n",
    "    index = np.argmax(result)\n",
    "    print(\"predicted index: {}\".format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
